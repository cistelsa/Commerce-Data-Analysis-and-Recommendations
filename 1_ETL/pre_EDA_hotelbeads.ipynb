{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ETL](<../5_Sources/Images/banner_etl.gif>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "\n",
    "## **Unificación de Datasets extraidos**\n",
    "\n",
    "</p>\n",
    "\n",
    "A través de la API se realiza extracción de multiples datasets en `JSON` por restricciones de la plataforma **HOTELBEDS** la cual permite en el caso de datos de HOTELES extraer por País y por lotes de 1000, su funcionalidad se limita a 50 extracciones cada 24H lo que nos indica que si tenemos aproximadamente **40Mil** Hoteles lo podemos hacer con una cuenta de API limitado a 40 lotes (40 extracciones) de archivos `JSON` para luego proceder a unificar y enviar directamente a realizarle `EDA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Parte de este script será reutilizado para agregar a la automatización</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos librería Pandas y Json para permitir la lectura de los archivos\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alistamos variables antes de realizar la iteración con `for`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa un DataFrame vacío\n",
    "df_hotels = pd.DataFrame()\n",
    "# Número total de conjuntos de datos que deseas leer\n",
    "num_datasets = 40\n",
    "# Ruta base donde se encuentran los archivos JSON\n",
    "path_base = \"../2_Datasets/original/hotelbeds/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos la iteración con `for` concatenando al mismo tiempo los datasets en JSON ya que tienen la misma estructura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera sobre los nombres de los archivos y los concatena en el DataFrame total\n",
    "for i in range(1, num_datasets + 1):\n",
    "    file_json = f\"hotels_us_total_api_{i}.json\"\n",
    "    path_file = path_base + file_json\n",
    "    \n",
    "    # Lee el archivo JSON y conviértelo en un DataFrame\n",
    "    df = pd.read_json(path_file)\n",
    "    \n",
    "    # Concatena el DataFrame actual al DataFrame total\n",
    "    df_hotels = pd.concat([df_hotels, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Importante`**: para la automatización y la extracción posterior debemos tener en cuenta la columna **`\"code\"`** con esta vamos a excluir en extracciones futuras datos repetidos, también nos ayuda a extraer los detalles de cada hotel y su disponibilidad de habitaciones en tiempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos un archivo csv su funcionalidad no va a ser a modo de dataset sino una forma de excluir data repetitiva en procesos automáticos\n",
    "df_hotels['code'].to_csv(path_base + \"hotels_code.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardamos la unificación del dataset para el proceso de EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataset en csv para la fácil lectura.\n",
    "df_hotels.to_csv(path_base + \"hotels_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
